\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsthm,amssymb,amsfonts,latexsym}
\usepackage{amsmath}

\usetheme{Warsaw}
\usepackage{ragged2e}
\apptocmd{\frame}{}{\justifying}{} % Allow optional arguments after frame.

\newtheorem{defi}{Definición}[section]
\newtheorem{theo}{Teorema}[section]
\newtheorem{corol}{Corolario}[section]



\setbeamertemplate{navigation symbols}{}
\addtobeamertemplate{navigation symbols}{}{%
    \usebeamerfont{footline}%
    \usebeamercolor[fg]{footline}%
    \hspace{1em}%
    \insertframenumber/\inserttotalframenumber
}
\setbeamertemplate{caption}[numbered]
%\addtobeamertemplate{block begin}{}{\justifying}


\title[Teoría Bayesiana]{Teoría Bayesiana}
\author[Julián Jiménez-Cárdenas]{Julián Jiménez-Cárdenas$^{1}$}
\institute{$^{1}$Universidad Nacional de Colombia, Bogotá. \and \texttt{juojimenezca@unal.edu.co}}
\date{}

\begin{document}

	\frame{\titlepage}
	\begin{frame}[allowframebreaks]

		\tableofcontents		
	\end{frame}
	
	\section{Preliminares}
	\subsection{Espacio de Probabilidad}
	\begin{frame}[allowframebreaks]{$\sigma$-álgebra}
	\begin{defi}[Experimento Aleatorio]
		Un experimento se dice aleatorio si su resultado no se puede determinar de antemano.
	\end{defi}
	\begin{defi}[Espacio de Muestra]
		El conjunto $\Omega$ de todos los posibles resultados de un experimento aleatorio se llama espacio de muestra. Un elemento $\omega\in\Omega$ se llama resultado o muestra. $\Omega$ se dice discreto si es finito o contable.
	\end{defi}	
	\begin{defi}[$\sigma$-álgebra]
		Tome $\Omega\neq\emptyset$. Una colección $\Im$ de subconjuntos de $\Omega$ se llama $\sigma-$álgebra sobre $\Omega$ si:
		\begin{enumerate}
			\item $\Omega\in\Im$,
			\item Si $A\in\Im$, entonces $A^c\in\Im$ y,
			\item Si $A_1,A_2,\dots\in\Im$, entonces $\bigcup_{i=1}^\infty A_i\in\Im$.
		\end{enumerate}
		Los elementos de $\Im$ se llaman eventos.
	\end{defi}
	\begin{theo}
		Si $\Omega\neq\emptyset$ y $\Im_1,\Im_2,\dots$ son $\sigma-$álgebras sobre $\Omega$, entonces $\bigcap_{i=1}^\infty \Im_i$ es una $\sigma$-álgebra sobre $\Omega$.
	\end{theo}		
	
	\begin{proof}
		Como $\Omega\in\Im_j,$ para $j=1,2,\dots$, $\Omega\in\bigcap_{j=1}^\infty \Im_j$. Si $A\in\bigcap_{j=1}^\infty\Im_j$, $A\in\Im_j$, para $j=1,2,\dots$, de modo que $A^c\in\Im_j$, y $A^c\in\bigcap_{j=1}^\infty\Im_j$. Por último, si 
		$$A_1,A_2,\dots\in\bigcap_{j=1}^\infty\Im_j,$$
		para todo $j=1,2,\dots$, $A_1,A_2,\dots\in\Im_j$, de modo que
		$$\bigcup_{i=1}^\infty A_i\in\Im_j\text{ y }\bigcup_{i=1}^\infty A_i\in\bigcap_{j=1}^\infty\Im_j.$$ 
	\end{proof}
	
	\begin{defi}[$\sigma$-álgebra generada]
		Tome $\Omega\neq\emptyset$ y $\mathcal{A}$ como una colección de subconjuntos de $\Omega$. Si $\mathcal{M}:=\{\Im:\Im\text{ es una }\sigma-\text{álgebra sobre }\Omega \text{ que contiene a } \mathcal{A}\},$
		$$\sigma(\mathcal{A}):=\bigcap_{\Im\in \mathcal{M}}\Im$$
		es la $\sigma-$álgebra más pequeña sobre $\Omega$ que contiene a $\mathcal{A}$. Esta $\sigma-$álgebra se conoce como $\sigma$-álgebra generada por $\mathcal{A}$.
	\end{defi}
	
	\begin{defi}[Espacio de medida]
		Tome $\Omega\neq\emptyset$ y sea $\Im$ una $\sigma$-álgebra sobre $\Omega$. La pareja $(\Omega,\Im)$ se llama espacio de medida.
	\end{defi}
	$\emptyset$ es el evento imposible. $\Omega$ es el evento seguro y $\{\omega\}$, con $\omega\in\Omega$ es un evento simple. Decimos que el evento $A$ ocurre después de llevar a cabo el experimento aleatorio si se obtiene un resultado en $A$, esto es, $A$ ocurre si el resultado es algún $\omega\in A$.
	\begin{enumerate}
		\item El evento $A\cup B$ ocurre si y sólo si $A$ ocurre, $B$ pasa, o ambos ocurren.
		\item El evento $A\cap B$ ocurre si y sólo si $A$ y $B$ ocurren a la vez.
		\item El evento $A^c$ ocurre si y sólo si $A$ no ocurre.
		\item El evento $A-B$ ocurre si y sólo si $A$ ocurre pero $B$ no ocurre.
	\end{enumerate}
	\begin{defi}[Eventos mutuamente excluyentes]
		Dos eventos $A$ y $B$ se dicen mutuamente excluyentes si $A\cap B=\emptyset$.
	\end{defi}
	
	\end{frame}
	
	\begin{frame}[allowframebreaks]{Espacio de probabilidad}
		\begin{defi}[Frecuencia relativa]
		Para cada evento $A$, el número $f_r(A):=\frac{n(A)}{n}$ se llama la frecuencia relativa de $A$, donde $n(A)$ indica el número de veces que ocurre $A$ en $n$ repeticiones del experimento aleatorio.
	\end{defi}
	Cuando $n\rightarrow\infty$, se puede hablar de la probabilidad de que ocurra el evento $A$, normalizada de $0$ a $1$. La formalización de este concepto se encuentra en la idea del espacio de probabilidad.
	
	\begin{defi}[Espacio de probabilidad]
		Tome $(\Omega,\Im)$ como un espacio de medida. Una función real $P$ sobre $\Im$ que satisface las siguientes condiciones:
		\begin{enumerate}
			\item $P(A)\geq0$ para todo $A\in\Im$ (no negativa),
			\item $P(\Omega)=1$ (normalizada) y,
			\item si $A_1,A_2,\dots$ son eventos mutuamente excluyentes en $\Im$, esto es, si
			$$A_i\cap A_j=\emptyset \text{ para todo }i\neq j, \text{ entonces}$$
			$$P\left(\bigcup_{i=1}^\infty A_i\right)=\sum_{i=1}^\infty P(A_i),$$
		\end{enumerate}
		se llama medida de probabilidad sobre $(\Omega,\Im)$. La tripleta $(\Omega,\Im,P)$ se llama espacio de probabilidad.
	\end{defi}
	\begin{theo}
		Si $(\Omega,\Im,P)$ es un espacio de probabilidad, entonces
		\begin{enumerate}
			\item $P(\emptyset)=\emptyset$.
			\item Si $A,B\in\Im$ y $A\cap B=\emptyset$, entonces $P(A\cup B)=P(A)+P(B).$
			\item Para todo $A\in\Im$, $P(A^c)=1-P(A).$
			\item Si $A\subseteq B$, entonces $P(A)\leq P(B)$ y $P(B-A)=P(B)-P(A).$ En particular, $P(A)\leq1$ para todo $A\in\Im$.
			\item Para todo $A,B\in\Im$, $P(A\cup B)=P(A)+P(B)-P(A\cap B)$.
			
		\end{enumerate}
	\end{theo}
	\begin{theo}
	\begin{enumerate}
	\setcounter{enumi}{5}
		\item Tome $\{A_n\}_n\subseteq\Im$ como una sucesión creciente, esto es, $A_n\subseteq A_{n+1}, \forall n\in\mathbb{N}$; entonces
			$$P\left(\lim_{m\rightarrow\infty}A_n\right)=\lim_{n\rightarrow\infty}P(A_n), \text{ donde } \lim_{n\rightarrow\infty} A_n:=\bigcup_{i=1}^\infty A_i.$$
		\item Tome $\{A_n\}_n\subseteq\Im$ como una sucesión decreciente, esto es, $A_n\supseteq A_{n+1}, \forall n\in\mathbb{N}$; entonces
			$$P\left(\lim_{m\rightarrow\infty}A_n\right)=\lim_{n\rightarrow\infty}P(A_n), \text{ donde } \lim_{n\rightarrow\infty} A_n:=\bigcap_{i=1}^\infty A_i.$$
	\end{enumerate}
	\end{theo}
	\begin{proof}
		\begin{enumerate}
			\item $1=P(\Omega\cup\emptyset\cup\emptyset\cup\cdots)=P(\Omega)+P(\emptyset)+P(\emptyset)+\cdots=1+P(\emptyset)+\cdots \implies P(\emptyset)=0.$
			\item $P(A\cup B)=P(A\cup B\cup\emptyset\cup\emptyset\cup\cdots)=P(A)+P(B).$
			\item $P(A)+P(A^c)=P(A\cup A^c)=P(\Omega)=1\implies P(A^c)=1-P(A).$
			\item Si $A\subseteq B$, $B=A\cup(B-A)$, de modo que $P(B)=P(A)+P(B-A).$ Como $P\geq0$, $P(B)\geq P(A)$ y $P(B-A)=P(B)-P(A).$ Si $B=\Omega,$ $P(A)\leq1.$
			\item Use el hecho de que $A\cup B=[A-(A\cap B)]\cup[B-(A\cap B)]\cup[A\cap B]$.			
		\end{enumerate}
		
	\end{proof}
	\begin{proof}
		\begin{enumerate}
		\setcounter{enumi}{5}
			\item Tome la sucesión $C_1=A_1,C_2=A_2-A_1,\dots,C_r=A_r-A_{r-1},\dots$. Es claro que
			$$\bigcup_{i=1}^\infty C_i=\bigcup_{i=1}^\infty A_i.$$
			Más aún, como $C_i\cap C_j=\emptyset\ \forall i\neq j,$ se sigue que
			$$P\left(\bigcup_{i=1}^\infty A_i\right)=P\left(\bigcup_{n=1}^\infty C_n\right)=\sum_{n=1}^\infty P(C_n)=\lim_{n\rightarrow\infty} \sum_{k=1}^n P(C_k)$$ $$=\lim_{n\rightarrow\infty}P\left(\bigcup_{k=1}^n C_k\right)=\lim_{n\rightarrow\infty}P\left(A_n\right).$$
			\item Tome la sucesión $\{B_n=A_n^c\}_n$ y aplique el resultado anterior.
		\end{enumerate}
	\end{proof}
	\end{frame}
	
	\begin{frame}[allowframebreaks]{Notas}
	Aplicando el teorema anterior de forma inductiva, para algunos eventos $A_1,A_2,\dots,A_n\in\Im$:
	\begin{align*}
	P(A_1\cup A_2\cup \cdots\cup A_n)=&\sum_{i=1}^n P(A_i)-\sum_{i_1<i_2}P(A_{i_{1}}\cap A_{i_{2}})+\cdots \\    
			& +(-1)^{r+1}\sum_{i_1<i_2<	\cdots<i_r}P(A_{i_1}\cap A_{i_2}\cap\cdots\cap A_{i_r})\\
			&+\cdots+(-1)^{n+1}P(A_1\cap A_2\cap \cdots\cap A_n).
	\end{align*}
	\noindent\rule{8cm}{0.4pt}
	
	Tome $(\Omega,\Im,P)$ como un espacio de probabilidad con $\Omega$ finito o contable y $\Im =\mathbb{P}(\Omega)$. Tome $\emptyset\neq A \in\Im.$ Es claro que
	
	$$A=\bigcup_{\omega\in A} \{\omega\}, \text{ de modo que }$$
	
	$$P(A)=\sum_{\omega\in A} P(\omega), \text{ donde } P(\omega):=P(\{\omega\}).$$
	Así, $P$ queda completamente definido por $p_j:=P(\omega_j)$, donde $\omega_j\in\Omega.$ El vector $|\Omega|-$dimensional $p:=(p_1,p_2,\dots)$ satisface las siguientes condiciones:
	\begin{itemize}
		\item $p_j\geq0$ y
		\item $\sum_{j=1}^\infty p_j=1.$
	\end{itemize}
	Un vector que satisface las anteriores condiciones se llama \textbf{vector de probabilidad}.	
	
	\end{frame}
	\subsection{Probabilidad Condicional e Independencia de Eventos}
	\begin{frame}{Introducción}
		Tome $B$ como un evento cuya opción de ocurrir debe ser medida bajo la suposición de que otro evento $A$ fue observado. Si el experimento se repite $n$ veces bajo las mismas circunstancias, entonces la frecuencia relativa de $B$ bajo la condición $A$ se define como
		$$f_r(B|A):=\frac{n(A\cap B)}{n(A)}=\frac{\frac{n(A\cap B)}{n}}{\frac{n(A)}{n}}=\frac{f_r(A\cap B)}{f_r(A)}, \text{ si }n(A)>0.$$
		Esto motiva la siguiente definición
	\end{frame}
	
	\begin{frame}[allowframebreaks]{Probabilidad Condicional}
		\begin{defi}[Probabilidad condicional]
			Tome $(\Omega, \Im, P)$ como un espacio de probabilidad. Si $A,B\in\Im$, con $P(A)>0$, entonces la probabilidad del evento $B$ bajo la condición $A$ se define como sigue
			$$P(B|A):=\frac{P(A\cap B)}{P(A).}$$
		\end{defi}
		El siguiente teorema provee algunas propiedades de la probabilidad condicional.
		\begin{theo}[Medida de probabilidad condicional]
			Tome $(\Omega, \Im, P)$ como un espacio de probabilidad y $A\in\Im$, con $P(A)>0$. Entonces:
			\begin{enumerate}
				\item $P(\cdot | A)$ es una medida de probabilidad sobre $\Omega$ centrada en $A$, esto es, $P(A|A)=1.$
				\item Si $A\cap B=\emptyset$, entonces $P(B|A)=0$.
				\item $P(B\cap C |A)=P(B|A\cap C)P(C|A)$ si $P(A\cap C)>0$.
				\item Si $A_1,A_2,\dots,A_n\in\Im$, con $P(A_1\cap A_2\cap\cdots\cap A_{n-1})>0$, entonces
				\begin{align*}
				P(A_1\cap A_2\cap\cdots\cap A_n)=P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)\cdots\\ P(A_n|A_1\cap A_2\cap \cdots\cap A_{n-1}).
				\end{align*}
			\end{enumerate}
		\end{theo}
		
		\begin{proof}
			\begin{enumerate}
				\item Las tres propiedades de una medida de probabilidad deben ser verificadas.
				\begin{enumerate}
					\item Claramente, $P(B|A)\geq0$ para todo $B\in\Im$.
					\item $P(\Omega | A)=\frac{P(\Omega\cap A}{P(A)}=\frac{P(A)}{P(A)}=1.$ También se tiene que $P(A|A)=1.$
					\item Tome $A_1,A_2,\dots\in\Im$ una sucesión de conjuntos disyuntos. Entonces
					\begin{align*}
					P\left(\bigcup_{i=1}^\infty A_i | A\right)=\frac{P\left(A\cap \bigcup_{i=1}^\infty A_i\right)}{P(A)}=\frac{P\left(\bigcup_{i=1}^\infty A\cap A_i\right)}{P(A)}\\
					=\sum_{i=1}^\infty \frac{P(A\cap A_i)}{P(A)}=\sum_{i=1}^\infty P(A_i | A).
					\end{align*}
				\end{enumerate}
			\end{enumerate}
		\end{proof}
		
		\begin{proof}
			\begin{enumerate}
				\setcounter{enumi}{1}
				\item Si $A\cap B=\emptyset$, $P(B|A)=\frac{P(A\cap B)}{P(A)}=\frac{P(\emptyset)}{P(A)}=0.$
				\item $P(B\cap C|A)=\frac{P(A\cap B\cap C)}{P(A)}=\frac{P(B\cap C\cap A)}{P(A\cap C)}\frac{P(C\cap A)}{P(A)}=P(B|A\cap C)P(C| A).$
				\item $P(A_1\cap\cdots\cap A_n)=\frac{P(A_1\cap\cdots\cap A_n)}{P(A_1\cap\cdots\cap A_{n-1})}\frac{P(A_1\cap\cdots\cap A_{n-1})}{P(A_1\cap\cdots\cap A_{n-2})}\cdots\frac{P(A_1\cap A_2)}{P(A_1)}P(A_1)=P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)\cdots P(A_n|A_1\cap A_2\cap \cdots\cap A_{n-1}).$
			\end{enumerate}
		\end{proof}
		\end{frame}
		
		\begin{frame}[allowframebreaks]{Teorema probabilidad total}
		Los siguientes resultados son vitales para aplicaciones posteriores.
		\begin{theo}[Teorema de probabilidad total]
			Tome $A_1,A_2,\dots$ como una partición finita o contable de $\Omega$, esto es, $A_i\cap A_j=\emptyset, \forall i\neq j$ y $\bigcup_{i=1}^\infty A_i=\Omega,$ tal que $P(A_i)>0$, para todo $A_i\in\Im$. Entonces, para todo $B\in\Im$:
			$$P(B)=\sum_{i} P(B|A_i)P(A_i).$$
		\end{theo}
		\begin{proof}
			Observe que
			$$B=B\cap\Omega=B\cap\left( \bigcup_{i=1}^\infty A_i \right)=\bigcup_{i=1}^\infty B\cap A_i,$$
			de modo que
			$$P(B)=P\left(\bigcup_{i=1}^\infty B\cap A_i\right)=\sum_{i=1}^\infty P(B\cap A_i)=\sum_{i=1}^\infty P(B| A_i)P(A_i).$$
		\end{proof}
		\end{frame}
		
		\begin{frame}[allowframebreaks]{Regla de Bayes}
		Como corolario del teorema anterior, se obtiene un resultado conocido como \textbf{regla de Bayes}, que constituye la base para la \textbf{teoría Bayesiana}.
		\begin{corol}[Regla de Bayes]
			Tome $A_1,A_2,\dots$ como una partición finita o contable de $\Omega$ con $P(A_i)>0$, para todo $i$; entonces, para todo $B\in\Im$ con $P(B)>0:$
			$$P(A_i | B)=\frac{P(A_i)P(B| A_i)}{\sum_j P(B|A_j)P(A_j)}, \forall i.$$
		\end{corol}
		\begin{proof}
		$$P(A_i|B)=\frac{P(A_i\cap B)}{P(B)}=\frac{P(A_i)P(B|A_i)}{P(B)}=\frac{P(A_i)P(B| A_i)}{\sum_j P(B|A_j)P(A_j)}.$$
		Con la partición $A_1=A, A_2=A^c$ se obtiene la forma usual de la regla de Bayes.
	\end{proof}
	\end{frame}
	
	\begin{frame}{Distribuciones a priori y a posteriori}
	\begin{defi}[Distribuciones a priori y a posteriori]
		Tome $A_1,A_2,\dots$ como una partición finita o contable de $\Omega$, con $P(A_i)>0$, para todo $i$. Si $P(B)>0$, con $B\in\Im$, entonces $\{P(A_n)\}_n$ se llama distribución a priori (antes de que $B$ ocurra), y $\{P(A_n|B)\}_n$ se llama distribución a posteriori (después de que $B$ ocurra).
	\end{defi}
	Algunas veces, la ocurrencia de un evento $B$ no afecta la probabilidad de un evento $A$, es decir,
	$$P(A|B)=P(A).$$
	En este caso, se dice que el evento $A$ es independiente del evento $B$. Esto motiva la siguiente definición.
	\end{frame}
	
	\begin{frame}[allowframebreaks]{Eventos Independientes}
	\begin{defi}[Eventos independientes]
		Dos eventos $A$ y $B$ se dicen independientes si y sólo si
		
		$$P(A\cap B)=P(A)P(B).$$
		Si esta condición no se tiene, se dice que los eventos son dependientes.
	\end{defi}
	\end{frame}
	\subsection{Variables aleatorias}
	\begin{frame}[allowframebreaks]{Variables aleatorias}
	\begin{defi}[Variable aleatoria]
	Tome $(\Omega, \Im, P)$ como un espacio de probabilidad. Una variable aleatoria es un mapa $X:\Omega\rightarrow \mathbb{R}$ tal que, para todo $A\in\mathbb{B}$, $X^{-1}(A)\in\Im$, donde $\mathbb{B}$ es la $\sigma$-álgebra de Borel sobre $\mathbb{R}$ ($\sigma$-álgebra más pequeña que contiene todos los intervalos de la forma $(-\infty, a]$).
	
		El conjunto de posibles valores de $X$ es $\mathbb{S}:=\{x\in\mathbb{R}:\exists \omega\in\Omega\text{ tal que }X(\omega)=x\}$, conocido como \textbf{soporte de la variable aleatoria }$X$.
	\end{defi}
	
	Si $X$ es una variable aleatoria definida sobre un  espacio de probabilidad $(\Omega, \Im, P)$, se introduce la notación
	$$\{X\in B\}:=\{\omega\in\Omega: X(\omega)\in B\}, \text{ con }B\in\mathbb{B}.$$
	
		\begin{defi}[Variable aleatoria discreta]
		Una variable aleatoria $X$ se dice discreta cuando el soporte $\mathbb{S}$ de $X$ es un subconjunto finito o contable de $\mathbb{R}$. Para $x\in\mathbb{S}$, la función $f(x)=P(X=x)$ se llama función de densidad de probabilidad (pdf para abreviar).
	\end{defi}
	
	\begin{defi}[Variable aleatoria continua]
		Una variable aleatoria $X$ se dice continua si el soporte $\mathbb{S}$ de $X$ es la unión de uno o más intervalos y si existe una función no negativa y real $f(x)$ tal que $P(X\leq x)=\int_{-\infty}^x f(t)\mathrm{d}t.$ La función $f(x)$ se llama función de densidad de probabilidad (pdf).
	\end{defi}
	\vspace{2cm}
	Algunas propiedades de la \textit{pdf} discreta son las siguientes:
	\begin{enumerate}
		\item $f(x)\geq0, \forall x\in\mathbb{S}$ y $f(x)=0,\forall x\not\in \mathbb{S}$.
		\item $\sum_{x\in\mathbb{S}}f(x)=1$.
		\item $P(X\in B)=\sum_{x\in B} f(x).$
	\end{enumerate}
	Análogamente, para la \textit{pdf} continua:
	\begin{enumerate}
		\item $f(x)\geq0, \forall x\in\mathbb{S}$ y $f(x)=0,\forall x\not\in \mathbb{S}$.
		\item $\int_{\mathbb{S}}f(x)\mathrm{d}x=1$.
		\item $P(X\in B)=\int_{B}f(x)\mathrm{d}x.$
	\end{enumerate}
	\begin{defi}[Función de distribución acumulativa]
		La función de distribución acumulativa (CDF, para abreviar) de una variable aleatoria se define como la función $F(x)=P(X\leq x)$.
	\end{defi}
	El siguiente teorema resume algunas propiedades importantes de una \textit{CDF}. 
	
	\begin{theo}
		Si $X$ es una variable aleatoria, con \textit{CDF} $F(x)$, entonces:
		\begin{enumerate}
			\item $\lim_{x\rightarrow-\infty}F(x)=0$ y $\lim_{x\rightarrow\infty} F(x)=1.$
			\item $F(x)$ es no decreciente; esto es, $F(x)\leq F(y)$, siempre que $x\leq y$.
			\item $F(x)$ es continua por derecha.
			\item $P(a< X \leq b)=F(b)-F(a).$
		\end{enumerate}
	\end{theo}
	
		\begin{theo}
		Si $X$ es una variable aleatoria discreta con \textit{CDF} $F(x)$ y soporte $\mathbb{S}=\{x_0,x_1,\dots\}$, con $x_0<x_1<\cdots$, entonces, para $x_k\in\mathbb{S}$,
		$$f(x_k)=F(x_k)-F(x_{k-1}).$$
	\end{theo}
	
	\begin{theo}
		Para una variable aleatoria continua, $f(x)=\frac{\mathrm{d}F}{\mathrm{d}x}, \forall x\in\mathbb{R}.$
	\end{theo}
	\end{frame}
	\subsection{Vectores Aleatorios}	
	\begin{frame}[allowframebreaks]{Vectores Aleatorios}
	\begin{defi}[Vector aleatorio]
		Un vector aleatorio $\vec{X}=(X_1,X_2,\dots,X_k)$ es un vector $k-$dimensional, donde $X_1,\dots,X_k$ son variables aleatorias. Un vector aleatorio se dice discreto cuando cada una de las variables aleatorias que lo conforman son discretas, y continuo cuando son continuas.
	\end{defi}
	
	\begin{defi}[Variable aleatoria bivariada]
		Un vector aleatorio bidimensional $\vec{X}=(X_1,X_2)$ se llama variable aleatoria bivariada.
	\end{defi}
	\vspace{2cm}
	De modo similar al caso de las variables aleatorias, los vectores aleatorios tienen \textit{pdf}, un soporte y una \textit{CDF}. El soporte de un vector aleatorio $k-$dimensional es el conjunto de valores que puede tomar, denotado por $\mathbb{S}_{\vec{X}}\subseteq\mathbb{R}^k.$
	
	\begin{defi}[Función de densidad de probabilidad adjunta discreta]
		Tome $\vec{X}$ como un vector aleatorio discreto $k-$dimensional. La \textit{pdf} adjunta de $\vec{X}$ se define como
		$$f(\vec{x}):=f(x_1,x_2,\dots,x_k)=P(X_1=x_1,X_2=x_2,\dots, X_k=x_k)$$
		para $\vec{x}=(x_1,x_2,\dots,x_k)\in\mathbb{S}_{\vec{X}}.$
	\end{defi}
	\vspace{2cm}
	La \textit{pdf} adjunta discreta tiene las siguientes propiedades:
	\begin{enumerate}
		\item $0\leq f(x_1,x_2,\dots,x_k)\leq1, \forall \vec{x}\in\mathbb{S}_{\vec{X}}.$
		\item $\sum_{\vec{x}\in\mathbb{S}_{\vec{X}}}f(\vec{x})=1.$
		\item Para cualquier subconjunto $B\subseteq \mathbb{S}_{\vec{X}},\ P(\vec{X}\in B)=\sum_{\{\vec{x}\in\mathbb{S}_{\vec{X}}:\vec{x}\in B\}}f(\vec{x}).$
	\end{enumerate}
	
	\begin{defi}[Función de densidad de probabilidad adjunta continua]
		Tome $\vec{X}$ como un vector aleatorio $k$-dimensional continuo. La \textit{pdf} continua de $\vec{X}$ se define como cualquier función no negativa $f(\vec{x})$ que satisfaga las siguientes propiedades:
		\begin{enumerate}
			\item $f(x_1,\dots,x_k)>0, \forall \vec{x}\in\mathbb{S}_{\vec{X}}.$
			\item $\int_{\mathbb{S}_{\vec{X}}} f(x_1,\dots,x_k)\mathrm{d}x_1\cdots\mathrm{d}x_k=1.$
			\item Para cualquier subconjunto $B\subset\mathbb{S}_{\vec{X}},\ P(\vec{X}\in B)=\int_{B}f(x_1,\dots,x_k)\mathrm{d}x_1\cdots\mathrm{d}x_k.$
		\end{enumerate}
	\end{defi}
	
	\begin{defi}[Función de distribución acumulativa adjunta]
		Tome $\vec{X}=(X_1,X_2,\dots,X_k)$ como un vector aleatorio $k-$dimensional. La \textit{CDF} adjunta de $\vec{X}$ se define como
		$$F(x_1,x_2,\dots,x_k)=P(X_1\leq x_1, X_2\leq x_2,\dots, X_k\leq x_k)$$ $$\ \forall (x_1,\dots,x_k)\in\mathbb{R}^k.$$
	\end{defi}
	
	\begin{defi}[Función de densidad de probabilidad marginal]
		Tome $\vec{X}=(X_1,\dots,X_k)$ como un vector aleatorio $k-$dimensional. La función de densidad de probabilidad marginal de la variable aleatoria $X_i$ es, para los casos discreto y continuo:
		

		$$f_i(x_i)=\underbrace{\sum_{x_1\in\mathbb{S}_{X}}\cdots \sum_{x_k\in\mathbb{S}_{X_k}}}_{\text{quitando la suma sobre }x_i} f(x_1,\dots,x_k)$$
		$$f_i(x_i)=\underbrace{\int_{x_1\in\mathbb{S}_{X_1}}\cdots \int_{x_k\in\mathbb{S}_{X_k}}}_{\text{quitando la integral sobre }x_i} f(x_1,\dots,x_k)\prod_{n\neq i}\mathrm{d}x_n$$ 
	\end{defi}
	
	\begin{defi}[Función de densidad de probabilidad condicional]
		Tome $\vec{X}(X_1,\dots,X_k)$ como un vector aleatorio $k-$dimensional. Para un valor fijo de $x_i$, donde $f_i(x_i)>0$, la función de densidad de probabilidad condicional para $\vec{Y}|X_i$; donde $\vec{Y}$ es un vector aleatorio $(k-1)-$dimensional con todas las variables aleatorias de $\vec{X}$, a excepción de $X_i$; es
		$$f(\vec{y}|x_i)=\frac{f(x_1,\dots,x_k)}{f_i(x_i)},$$
		donde $\vec{y}\in\mathbb{S}_{\vec{Y}}.$
	\end{defi}
	\begin{defi}[Colección independiente de variables aleatorias]
	Una colección de variables aleatorias $\{ X_1,X_2,\dots, X_k\}$ se dice independiente cuando
	$$F(x_1,x_2,\dots,x_k)=\prod_{i=1}^k F_i(x_i), \forall\vec{x}\in\mathbb{R}^k,$$
	donde $F_i(x_i)$ es la \textit{CDF} marginal de la variable aleatoria $X_i$ (determinada a partir de la \textit{pdf} marginal: $F_i(x_i):=P(X_i\leq x_i)$).
	\end{defi}
	
	\begin{defi}[Colección independiente de variables aleatorias]
	También se puede definir la independencia entre variables aleatorias usando las pdf, en el sentido de que la misma colección de variables aleatorias se dice independiente cuando
	$$f(x_1,x_2,\dots,x_k)=\prod_{i=1}^k f_i(x_i), \forall\vec{x}\in\mathbb{S}_{\vec{X}},$$
	donde $f_i(x_i)$ es la pdf marginal asociada a la variable aleatoria $X_i$.
	
	\end{defi}
	
		\begin{defi}[Colección de variables aleatorias independientes idénticamente distribuidas]
		Una colección de variables aleatorias $\{ X_1,X_2,\dots, X_k\}$ se dice independiente e idénticamente distribuidas (iid, para abreviar) si y sólo si $X_1,X_2,\dots,X_k$ son variables aleatorias independientes y la pdf de cada variable aleatoria es idéntica.
	\end{defi}
	
	\end{frame}
	\section{Función de Verosimilitud}
	\subsection{Estadística}
	\begin{frame}{Estimación paramétrica}
	\begin{enumerate}
			\item Un modelo probabilístico $f(x,\theta)$, especificado con los valores de los parámetros desconocidos.
			\item Un conjunto de posibles valores de $\theta$ bajo consideración, llamado el espacio de parámetros, denotado por $\Theta$.
			\item Una muestra aleatoria de $n$ observaciones del modelo probabilístico.
			\item Un conjunto de estimadores puntuales para los valores de los parámetros desconocidos, basados en la información contenida en la muestra aleatoria.
			\item Las propiedades específicas de los estimadores que permiten evaluar la precisión y eficiencia del estimador.
		\end{enumerate}
	\end{frame}
	
	\begin{frame}[allowframebreaks]{Muestra y Estadística}
	\begin{defi}[Muestra]
			Una colección de variables aleatorias $X_1,\dots,X_k$ se llama muestra de tamaño $n$. Una muestra de $n$ variables aleatorias independientes $X_1,\dots,X_n$ se llama muestra aleatoria.
		\end{defi}
		
		\begin{defi}[Estadística y estimador]
			Dada una muestra $X_1,X_2,\dots,X_n$, una estadística $T=T(X_1,\dots,X_n)$ es una función de la muestra que no depende de ningún otro parámetro desconocido. Un estimador es una estadística que se usa para determinar una cantidad desconocida, y el estimado es el valor observado del estimador (evaluando la función en la muestra).
		\end{defi}
		
		\begin{defi}[Distribución muestral]
			Para una muestra $X_1,\dots, X_n$ y una estadística $T=T(X_1,\dots,X_n)$, la distribución muestral de la estadística $T$ es la distribución de probabilidad asociada a la variable aleatoria $T$. La pdf de la distribución muestral se denota como $f_T(t;\theta)$.
		
		\end{defi}
		
		\begin{defi}[Valor esperado]
			Tome $X$ como una variable aleatoria con pdf $f(x)$ en $\mathbb{S}_X$. El valor esperado de la variable aleatoria $X$, denotado por $E(X)$, se define como 
			$$E(X)=\sum_{x\in\mathbb{S}_X} xf(x)$$
			cuando $X$ es una variable aleatoria discreta, y como
			$$E(X)=\int_{x\in\mathbb{S}_X} xf(x)\mathrm{d}x$$
			cuando $X$ es una variable aleatoria continua.
		\end{defi}
		
		\begin{defi}[Estimador imparcial]
		Una estadística $T$ se dice estimador imparcial de un parámetro $\theta$ cuando $E(T)=\theta$, $\forall \theta\in\Theta$. Una estadística se conoce como estimador parcial de $\theta$ cuando $E(T)\neq \theta$, y la parcialidad de una estadística $T$ para estimar un parámetro $\theta$ se define como  $\mathop{Bias}(T;\theta)=E(T)-\theta.$ 
	\end{defi}
	
	\begin{defi}[Estimador asintóticamente imparcial]
		Una estadística $T_n=T(X_1,\dots,X_n)$ se conoce como estimador asintóticamente imparcial de un parámetro $\theta$ cuando $$\lim_{n\rightarrow\infty}\mathop{Bias}(T_n;\theta)=0.$$
	\end{defi}
	
	Algunas variables útiles para determinar la precisión y exactitud del estimador son las siguientes:
	
	$$\mathop{SE}(T):=\sqrt{\mathop{E}((T-E(T))^2)}:=\sqrt{\mathop{Var}(T)}.$$
	
	$$\mathop{MSE(T;\theta)}=\mathop{E}((T-\theta)^2).$$
	
	Una estadística que contiene toda la información relevante acerca de $\theta$ en una muestra se conoce como estadística suficiente.
	
	\begin{defi}[Estadística suficiente]
		Tome $X_1,\dots,X_n$ como una muestra de variables aleatorias \textit{iid} con \textit{pdf} común $f(x;\theta)$, para $\theta\in\Theta\subseteq\mathbb{R}^d$. Un vector de estadísticas $\vec{S}(\vec{X}):=(S_1(\vec{X}),\dots, S_k(\vec{X}))$ se dice que es una estadística suficiente $k-$dimensional para un parámetro $\theta$ si y sólo si la distribución condicional de $\vec{X}$ dado $S=s$ no depende de $\theta$, para ningún valor de $s$.
	\end{defi}
		%=================================
		\begin{defi}[Función de verosimilitud]
			Para una muestra $X_1,\dots,X_n$, la función de verosimilitud $L(\theta|\vec{X})$ es la pdf adjunta de $\vec{X}=(X_1,\dots,X_n)$, es decir,
$$L(\theta|\vec{X})=f(x_1,\dots,x_n;\theta)$$			
			La función logarítmica de verosimilitud $\ell(\theta)$ se define como el logaritmo de la función de verosimilitud.
		\end{defi}
		
		Cuando $X_1,\dots,X_n$ es una muestra de variables aleatorias \textit{iid}, se puede escribir la función de verosimilitud como
		$$L(\theta)=\prod_{i=1}^n f(x_i;\theta).$$
		
		\begin{theo}[Teorema de factorización de Neyman-Fisher]
			Tome $X_1,\dots,X_n$ como una muestra de variables aleatorias iid con pdf $f(x;\theta)$, y espacio de parámetros $\Theta$. Una estadística $S(\vec{X})$ es suficiente para $\theta$ si y sólo si $L(\theta)$ se puede factorizar como
			$$L(\theta)=g(S(\vec{x});\theta)h(\vec{x}),$$
			donde $g(S(\vec{x});\theta)$ no depende de $\vec{x}=(x_1,\dots,x_n)$, excepto a través de $S(\vec{x})$, y $h(\vec{x})$ no depende de $\theta$.
		\end{theo}
		
		\end{frame}
		\begin{frame}[allowframebreaks]
		
		\begin{block}{Ley de verosimilitud}
		Tome $X_1,\dots,X_n$ como una muestra de variables aleatorias \textit{iid} con \textit{pdf} común $f(x;\vec{\theta})$ y espacio de parámetros $\Theta$. Para $\vec{\theta}\in\Theta$, mientras mayor sea el valor de $L(\vec{\theta})$, el modelo probabilístico con parámetro $\vec{\theta}$ se ajusta más a los datos observados. Entonces, el grado con el cual la información de la muestra da soporte a un parámetro $\vec{\theta}_0\in\Theta$, en comparación con otro parámetro $\vec{\theta}_1\in\Theta$ es igual a la razón entre sus verosimilitudes
		$$\Lambda(\vec{\theta}_0,\vec{\theta}_1)=\frac{L(\vec{\theta}_0)}{L(\vec{\theta}_1)}.$$
		\end{block}
		
		\begin{defi}[Función de Score]
			Tome $X_1,\dots,X_n$ como una muestra de variables aleatorias con función de verosimilitud $L(\vec{\theta})$, para $\vec{\theta}\in\Theta$. Si la función de verosimilitud logarítmica $\ell(\vec{\theta})$ es diferenciable, la función de Score se define como
			
			$$\mathop{Sc}(\vec{\theta})=\nabla_{\vec{\theta}}\ \ell(\theta),$$
			de tal modo que una condición necesaria para que $\vec{\theta}\in\Theta$ sea un máximo es que $\mathop{Sc}(\theta)=\vec{0}.$
		\end{defi}
	\end{frame}
	
	\subsection{Estimación bayesiana}
	
	\begin{frame}[allowframebreaks]{Estimación bayesiana}
		En la estimación paramétrica puntual bayesiana, el parámetro $\theta$ se trata como una variable aleatoria, con su propia \textit{pdf} $\pi(\theta;\lambda)$.
		
		Las inferencias de $\theta$ en la aproximación bayesiana están basadas en la distribución de $\theta$ dados los valores observados de una muestra aleatoria $\vec{x}=(x_1,\dots,x_n)$, llamada distribución posterior, y denotada por $f(\theta | \vec{x})$.
		
		Usando el teorema de Bayes y el teorema de la probabilidad total, en el caso de que $\theta$ es una variable aleatoria continua,
		
		$$f(\theta | \vec{x})=\frac{f(\vec{x},\theta;\lambda)}{f_{\vec{X}}(\vec{x})}=\frac{f(\vec{x}|\theta)\pi(\theta;\lambda)}{\int_{\mathbb{S}_\theta}f(\vec{x}|\theta)\pi(\theta;\lambda)\mathrm{d}\theta}.$$
		
		De modo similar, cuando $\theta$ es una variable aleatoria discreta,
		
		$$f(\theta|\vec{x})=\frac{f(\vec{x}|\theta)\pi(\theta;\lambda)}{\sum_{\theta\in\mathbb{S}_\theta}f(\vec{x}|\theta)\pi(\theta;\lambda)}.$$
		
		La distribución posterior combina la información disponible de $\theta$ en la distribución previa y la función de verosimilitud para producir una distribución actualizada que contiene toda la información disponible de $\theta$.
		
El siguiente teorema indica que la distribución posterior depende de la muestra $\vec{x}$ sólo bajo una estadística suficiente para $\theta$.
		
		\begin{theo}
			Si $X_1,\dots,X_n$ es una muestra de variables independientes iid con pdf común $f(x|\theta)$, $S$ es una estadística suficiente para $\theta$, y $\pi(\theta;\lambda)$ una distribución previa para $\theta$, entonces la distribución posterior de $\theta$ dado $\vec{X}$ depende de la muestra sólo a través de una estadística suficiente $S$.
		\end{theo}
	\end{frame}
	\section{Referencias}
	\begin{frame}
	\frametitle{Referencias}

	\nocite{*}
	\bibliographystyle{plain}
	\bibliography{referenciasExpo}

	\end{frame}
	%=======================================================
	\end{document}